#!/usr/bin/env python3
"""
Guide pour r√©cup√©rer les VRAIES donn√©es de l'ASSE saison 2003-2004
Ce script explique comment utiliser les APIs qui ont des donn√©es historiques
"""

import requests
import json

# ============================================================================
# OPTION 1: API-Football (Recommand√© pour donn√©es historiques)
# ============================================================================

def get_asse_matches_api_football(api_key, season_year):
    """
    R√©cup√®re les matchs de l'ASSE via API-Football
    API-Football a des donn√©es depuis 2010 environ
    
    Pour 2003-2004, les donn√©es peuvent √™tre limit√©es
    """
    
    BASE_URL = "https://v3.football.api-sports.io"
    
    headers = {
        'x-rapidapi-host': 'v3.football.api-sports.io',
        'x-rapidapi-key': api_key
    }
    
    # ID de l'ASSE dans API-Football
    ASSE_ID = 1063
    
    # R√©cup√©rer tous les matchs de l'ASSE pour la saison
    url = f"{BASE_URL}/fixtures"
    params = {
        'team': ASSE_ID,
        'season': season_year
    }
    
    try:
        response = requests.get(url, headers=headers, params=params)
        response.raise_for_status()
        data = response.json()
        
        if data.get('response'):
            matches = data['response']
            print(f"‚úÖ {len(matches)} matchs trouv√©s pour la saison {season_year}")
            return matches
        else:
            print(f"‚ùå Aucun match trouv√© pour la saison {season_year}")
            print(f"   Raison possible: Donn√©es historiques non disponibles")
            return []
            
    except requests.exceptions.HTTPError as e:
        print(f"‚ùå Erreur HTTP: {e}")
        return []
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        return []

# ============================================================================
# OPTION 2: Web Scraping (Alternative pour donn√©es tr√®s anciennes)
# ============================================================================

def get_historical_data_info():
    """
    Informations sur comment obtenir des donn√©es historiques de 2003-2004
    """
    
    print("\n" + "="*80)
    print("üìö SOURCES DE DONN√âES HISTORIQUES POUR LA SAISON 2003-2004")
    print("="*80)
    
    sources = [
        {
            "nom": "Transfermarkt",
            "url": "https://www.transfermarkt.com/as-saint-etienne/spielplandatum/verein/618/saison_id/2003",
            "type": "Site Web",
            "avantages": [
                "Donn√©es compl√®tes depuis les ann√©es 1960",
                "Tous les matchs, buteurs, cartons",
                "Compositions d'√©quipes",
                "Gratuit"
            ],
            "inconvenients": [
                "Pas d'API officielle",
                "N√©cessite du web scraping",
                "Risque de blocage si trop de requ√™tes"
            ]
        },
        {
            "nom": "Soccerway",
            "url": "https://www.soccerway.com/teams/france/as-saint-etienne/",
            "type": "Site Web",
            "avantages": [
                "Donn√©es historiques compl√®tes",
                "Interface claire",
                "Statistiques d√©taill√©es"
            ],
            "inconvenients": [
                "Pas d'API",
                "Web scraping n√©cessaire"
            ]
        },
        {
            "nom": "BeSoccer API",
            "url": "https://www.besoccer.com/api",
            "type": "API Payante",
            "avantages": [
                "Donn√©es depuis 1990",
                "API officielle",
                "Donn√©es structur√©es"
            ],
            "inconvenients": [
                "Payant (√† partir de 10‚Ç¨/mois)",
                "N√©cessite inscription"
            ]
        },
        {
            "nom": "Sportmonks",
            "url": "https://www.sportmonks.com/football-api/",
            "type": "API Payante",
            "avantages": [
                "Donn√©es historiques tr√®s compl√®tes",
                "Toutes les comp√©titions",
                "Statistiques avanc√©es"
            ],
            "inconvenients": [
                "Payant (√† partir de 19‚Ç¨/mois)",
                "Plan gratuit tr√®s limit√©"
            ]
        },
        {
            "nom": "Wikipedia",
            "url": "https://fr.wikipedia.org/wiki/Saison_2003-2004_de_l%27AS_Saint-%C3%89tienne",
            "type": "Site Web",
            "avantages": [
                "Gratuit",
                "R√©sum√© de la saison",
                "Principaux r√©sultats"
            ],
            "inconvenients": [
                "Donn√©es limit√©es",
                "Pas d'API",
                "Pas de statistiques d√©taill√©es"
            ]
        }
    ]
    
    for i, source in enumerate(sources, 1):
        print(f"\n{i}. {source['nom']}")
        print(f"   üîó {source['url']}")
        print(f"   üìã Type: {source['type']}")
        print(f"   ‚úÖ Avantages:")
        for avantage in source['avantages']:
            print(f"      ‚Ä¢ {avantage}")
        print(f"   ‚ùå Inconv√©nients:")
        for inconvenient in source['inconvenients']:
            print(f"      ‚Ä¢ {inconvenient}")

# ============================================================================
# OPTION 3: Exemple de Web Scraping (Transfermarkt)
# ============================================================================

def example_web_scraping():
    """
    Exemple de code pour scraper Transfermarkt
    ATTENTION: Respectez les conditions d'utilisation du site
    """
    
    print("\n" + "="*80)
    print("üíª EXEMPLE DE WEB SCRAPING (Transfermarkt)")
    print("="*80)
    
    code_example = '''
import requests
from bs4 import BeautifulSoup
import time

def scrape_asse_season_2003_2004():
    """
    Exemple de scraping pour r√©cup√©rer les matchs de l'ASSE 2003-2004
    """
    
    url = "https://www.transfermarkt.com/as-saint-etienne/spielplandatum/verein/618/saison_id/2003"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    try:
        # Respecter un d√©lai entre les requ√™tes
        time.sleep(2)
        
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Trouver le tableau des matchs
        matches_table = soup.find('table', class_='items')
        
        if matches_table:
            matches = []
            rows = matches_table.find_all('tr', class_=['odd', 'even'])
            
            for row in rows:
                # Extraire les donn√©es de chaque match
                # (Le code exact d√©pend de la structure HTML)
                pass
            
            return matches
        
    except Exception as e:
        print(f"Erreur: {e}")
        return []

# IMPORTANT: Respectez les conditions d'utilisation
# - Ajoutez des d√©lais entre les requ√™tes (time.sleep)
# - Ne faites pas trop de requ√™tes
# - V√©rifiez le fichier robots.txt du site
'''
    
    print("\n‚ö†Ô∏è  AVERTISSEMENT:")
    print("   - Le web scraping doit respecter les conditions d'utilisation des sites")
    print("   - Ajoutez toujours des d√©lais entre les requ√™tes")
    print("   - V√©rifiez le fichier robots.txt")
    print("   - Pr√©f√©rez les APIs officielles quand c'est possible")
    
    print("\nüìù Code d'exemple:")
    print(code_example)

# ============================================================================
# MAIN
# ============================================================================

def main():
    print("="*80)
    print("üîç GUIDE: R√©cup√©rer les matchs de l'ASSE saison 2003-2004")
    print("="*80)
    
    print("\n‚ö†Ô∏è  PROBL√àME: Les APIs gratuites modernes n'ont g√©n√©ralement pas")
    print("   de donn√©es aussi anciennes que 2003-2004")
    
    print("\nüí° SOLUTIONS DISPONIBLES:")
    
    # Afficher les sources de donn√©es
    get_historical_data_info()
    
    # Afficher l'exemple de web scraping
    example_web_scraping()
    
    print("\n" + "="*80)
    print("üéØ RECOMMANDATIONS")
    print("="*80)
    
    print("\n1Ô∏è‚É£  Pour un usage personnel/√©ducatif:")
    print("   ‚Üí Utilisez Wikipedia ou Transfermarkt (consultation manuelle)")
    
    print("\n2Ô∏è‚É£  Pour un projet n√©cessitant une API:")
    print("   ‚Üí BeSoccer API (10‚Ç¨/mois) - Donn√©es depuis 1990")
    print("   ‚Üí Sportmonks (19‚Ç¨/mois) - Donn√©es historiques compl√®tes")
    
    print("\n3Ô∏è‚É£  Pour un projet de web scraping:")
    print("   ‚Üí Transfermarkt (gratuit mais n√©cessite du code)")
    print("   ‚Üí Respectez les conditions d'utilisation")
    print("   ‚Üí Ajoutez des d√©lais entre les requ√™tes")
    
    print("\n4Ô∏è‚É£  Alternative: Saisons plus r√©centes")
    print("   ‚Üí Football-Data.org: Donn√©es depuis 2015 (GRATUIT)")
    print("   ‚Üí API-Football: Donn√©es depuis 2010 (Plan gratuit disponible)")
    
    print("\n" + "="*80)
    print("üì¶ FICHIERS UTILES")
    print("="*80)
    
    print("\n‚úÖ Fichiers cr√©√©s pour vous:")
    print("   ‚Ä¢ demo_asse_2003_2004.py - D√©monstration avec √©chantillon")
    print("   ‚Ä¢ asse_saison_2003_2004.json - Donn√©es d'exemple")
    
    print("\nüìù Pour tester avec des donn√©es r√©elles r√©centes:")
    print("   ‚Ä¢ test_football_data_org.py - API gratuite (saisons 2015+)")
    print("   ‚Ä¢ test_api_football.py - API-Football (saisons 2010+)")
    
    print("\n" + "="*80)
    print("‚úÖ GUIDE TERMIN√â")
    print("="*80)
    
    print("\n‚ùì Besoin d'aide?")
    print("   - Pour des saisons r√©centes (2015+): Utilisez Football-Data.org")
    print("   - Pour des donn√©es historiques: Consid√©rez BeSoccer API ou Sportmonks")
    print("   - Pour un usage ponctuel: Consultez Transfermarkt ou Wikipedia")

if __name__ == "__main__":
    main()
